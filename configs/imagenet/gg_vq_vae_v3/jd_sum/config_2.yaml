# ImageNet GG-VQ-VAE Configuration - JD Sum Aggregator (BCE)
# This configuration trains a GG-VQ-VAE on ImageNet dataset with BCE mean objectives


# Dataset settings
dataset: ImageNet
data_dir: ../data/imagenet
normalize: false
# Model architecture
arch: gg_vq_vae_v3
embedding_dim: 64
num_embeddings: 512
hidden_dims: [128, 256]
loss_weights: [1.0, 1.0, 0.25, 1.0, 1.0]
recons_dist: bernoulli
recons_reduction: mean
# Training settings
epochs: 20
batch_size: 128
optimizer: adam
lr: 2e-4
wd: 0.0
aggregator: jd_sum
seed: 42
device: cuda:5
num_workers: 8
# Logging settings
save_path: logs/
save_freq: 1
eval_freq: 1
num_samples: 4
# Hypervolume reference points (GG-VQ-VAE v3 has 5 objectives: reconstruction_loss, embedding_loss, commitment_loss, gradient_guided_loss, edge_matching_loss)
hv_ref: [1.1, 1.1, 1.1, 1.1, 1.1]
# Wandb settings
use_wandb: true
wandb_project: mo-vae
wandb_entity: rasa_research
wandb_name: imagenet gg_vq_vae_v3 512k 64d sum [1*bce + 1*embedding + 0.25*commitment + 1*gradient_guided + 1*edge_matching]

