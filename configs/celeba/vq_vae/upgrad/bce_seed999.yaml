# CELEBA VQ-VAE Configuration - UpGrad Aggregator (BCE + Embedding + Commitment)
# This configuration trains a VQ-VAE on CELEBA dataset with BCE mean and Embedding and Commitment objectives


# Dataset settings
dataset: CelebA
data_dir: ../data
normalize: false
# Model architecture
arch: vq_vae
embedding_dim: 64
num_embeddings: 512
hidden_dims: [128, 256]
loss_weights: [1.0, 1.0, 0.25]
recons_dist: bernoulli
recons_reduction: mean
# Hypervolume reference points (VQ-VAE has 3 objectives: reconstruction_loss, embedding_loss, commitment_loss)
hv_ref: [1.1, 1.1, 1.1]
# Training settings
epochs: 200
batch_size: 64
optimizer: adam
lr: 2e-4
wd: 0.0
aggregator: upgrad
seed: 999
device: cuda:0
num_workers: 6
# Logging settings
save_path: logs/
save_freq: 10
eval_freq: 10
num_samples: 64
# Wandb settings
use_wandb: true
wandb_project: mo-vae
wandb_entity: rasa_research
wandb_name: celeba vq_vae 512k 64d upgrad [1*bce + 1*embedding + 0.25*commitment] seed999

