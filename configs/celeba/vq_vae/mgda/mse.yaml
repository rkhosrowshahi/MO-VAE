# CELEBA VQ-VAE Configuration - MGDA Aggregator (MSE)
# This configuration trains a VQ-VAE on CELEBA dataset with MSE objectives

dataset: CelebA
data_dir: ../data
arch: vq_vae
epochs: 100
batch_size: 128
optimizer: adam
lr: 3e-4
wd: 0.0
aggregator: mgda
normalize: true

# Model architecture
embedding_dim: 64
num_embeddings: 512
hidden_dims: [128, 256]
loss_weights: [1.0, 1.0, 0.25]
recons_dist: gaussian
recons_reduction: mean

# Training settings
seed: 42
num_workers: 4
device: cuda:0
save_path: logs/
save_freq: 10
eval_freq: 10
num_samples: 64

# Hypervolume reference points
hv_ref: [1.1, 1.1, 1.1]

# Wandb settings (optional)
use_wandb: true
wandb_project: mo-vae
wandb_entity: rasa_research
wandb_name: "celeba vq_vae mse MGDA"

